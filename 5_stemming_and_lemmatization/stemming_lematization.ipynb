{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcef70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bb2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44410032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "runner  |  runner\n",
      "ran  |  ran\n",
      "easily  |  easili\n",
      "fairly  |  fairli\n"
     ]
    }
   ],
   "source": [
    "words = [\"running\", \"runner\", \"ran\", \"easily\", \"fairly\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b552d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run  |  12767647472892411841\n",
      "runner  |  runner  |  12640964157389618806\n",
      "ran  |  ran  |  6840958122370687302\n",
      "eat  |  eat  |  9837207709914848172\n",
      "eating  |  eat  |  9837207709914848172\n",
      "ate  |  eat  |  9837207709914848172\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"running runner ran eat eating ate\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_, \" | \",token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05bf0dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mando  |  Mando\n",
      "talked  |  talk\n",
      "for  |  for\n",
      "3  |  3\n",
      "hours  |  hour\n",
      "although  |  although\n",
      "talking  |  talk\n",
      "is  |  be\n",
      "n't  |  not\n",
      "his  |  his\n",
      "thing  |  thing\n",
      "he  |  he\n",
      "became  |  become\n",
      "really  |  really\n",
      "talkative  |  talkative\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing he became really talkative\")\n",
    "\n",
    "for token in doc: \n",
    "    print(token, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "922ff373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  Brother\n",
      ",  |  ,\n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brother\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe(\"attribute_ruler\")\n",
    "ar.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\": \"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
